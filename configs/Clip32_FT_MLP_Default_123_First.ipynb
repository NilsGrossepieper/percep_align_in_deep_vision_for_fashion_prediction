{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgd//BYtAYwVjbBRX1wN1a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jmhsN3mE-u3m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759496594677,"user_tz":-120,"elapsed":2636,"user":{"displayName":"Nils Großepieper","userId":"13858288233403889681"}},"outputId":"9cfbdbb6-69c7-459d-d64d-22e4df8b4567"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nqpS57oE-sHk","executionInfo":{"status":"ok","timestamp":1759496594713,"user_tz":-120,"elapsed":30,"user":{"displayName":"Nils Großepieper","userId":"13858288233403889681"}}},"outputs":[],"source":["\"\"\"\n","exp_configs.ipynb\n","\n","This script defines and saves the configuration for running forecasting experiments.\n","It specifies:\n","    - Global settings (experiment name, project root, random seed, melting option)\n","    - Dataset information (season and split method)\n","    - Embedding model configuration\n","    - Feature selection and PCA settings\n","    - Forecasting model parameters (KNN, Gradient Boosting, Random Forest, Ridge)\n","\n","The configuration is saved as a YAML file under the configs directory so that it\n","can be easily loaded by other scripts for reproducibility and consistent experiment runs.\n","\"\"\"\n","\n","import os\n","import yaml\n","import logging\n","\n","logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')\n","\n","config = {\n","    'global': {\n","        'project_name': 'sales-forecasting',\n","        'experiment_name': 'Clip32_FT_MLP_Default_123_First', # Naming style: Clip32_Vanilla_Default_123\n","        'forecasting_seed': 123, # Options: 123, 456, 789\n","        'melt_data': True,\n","        'wandb_bool': True,\n","        'project_root': '/content/drive/MyDrive/perceptual-vits-fashion-forecasting'\n","    },\n","\n","    'data': {\n","        'season': 'AW19', # Options: SS19, AW19\n","        'split_method': 'default' # Options: season, release_date, standard, week, default\n","    },\n","\n","    'features': {\n","        'using_year_int': False,\n","        'using_year_dummies': False,\n","        'using_season_dummies': False,\n","        'using_price_float': False,\n","        'using_category_dummies': False,\n","        'using_color_dummies': False,\n","        'using_fabric_dummies': False,\n","        'using_store_int': False,\n","        'using_store_dummies': True,\n","        'using_week_dummies': True,\n","        'pca': True,\n","        'n_components': 256,\n","        'visualize_pca': False\n","    },\n","\n","    'forecasting': {\n","        'knn': {\n","            'enabled': True,\n","            'dummy_normalization': True,\n","            'normalize_embeddings_manually': True,\n","            'error_metric': 'mse',\n","            'max_neighbors': 200,\n","            'weights': ['uniform', 'distance']\n","        },\n","        'gradient_boosting': {\n","            'enabled': True,\n","            'dummy_normalization': True,\n","            'normalize_embeddings_manually': True,\n","            'error_metric': 'mse',\n","            'n_trials': 40,\n","            'n_estimators': [300, 500, 700, 900],\n","            'learning_rate': [0.05, 0.07, 0.09, 0.11],\n","            'max_depth': [5, 7, 9, 11],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 3, 5]\n","        },\n","        'random_forest': {\n","            'enabled': True,\n","            'dummy_normalization': True,\n","            'normalize_embeddings_manually': True,\n","            'error_metric': 'mse',\n","            'n_trials': 40,\n","            'n_estimators': [300, 500, 700, 900],\n","            'max_depth': [7, 9, 11, 13],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 3, 5]\n","        },\n","        'ridge': {\n","            'enabled': True,\n","            'dummy_normalization': True,\n","            'normalize_embeddings_manually': True,\n","            'error_metric': 'mse',\n","            'alpha_values': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n","        }\n","    },\n","\n","    'vision_model':{\n","        'wandb_project': 'vision-model-training',\n","        'vision_model_seed': 123, # Options 123, 456, 789\n","        'model_family': 'vit', # Options: vit, cnn\n","        'model_type': 'clip_vitb32', # Naming style: clip_vitb32 or resnet50\n","        'train': True,\n","        'load_vit': False,\n","        'tag': 'Clip32_FT_MLP_First_Model', # Naming style: Clip32_Vanilla_First_Model\n","        'training_method': 'mlp', # Options: mlp, lora, no_training\n","        'dataset_name': 'fashion_triplets', # Options: none, nights, fashion_triplets, nights_fashion_triplets, synthetic_fashion\n","        'hidden_size': 512,\n","        'best': True,\n","\n","        'vit':{\n","            'log_dir': '/vision_models/vits_training',\n","            'load_dir': '/vision_models/vits_backbone_models',\n","            'save_mode': 'entire_model', # Options: adapter_only, entire_model, all\n","            'vision_model_training_name': 'Clip32_FT_MLP_First_Model', # Naming style: Clip32_Vanilla_First_Model\n","            'wandb_notes': 'Training run for the MLP Clip32 model on FT data.', # Naming style: Training run for the Vanilla Clip32 model on no data. or Training run for the Lora Clip32 model on NIGHTS data.\n","\n","            'feat_type': 'embedding',\n","            'stride': '32', # Options 16 or 32\n","            'use_lora': False,\n","            'normalize_embeds': True,\n","            'load_size': 224,\n","\n","            'dataset_root': '/content/datasets/fashion_triplets/', # Options: /content/datasets/nights/, /content/datasets/fashion_triplets/\n","            'second_dataset_root': None, # Options: /content/datasets/fashion_triplets/\n","\n","            'lr': 0.0001, # Big data: 0.0003, Small data: 0.0001\n","            'weight_decay': 0.0001, # Big data: 0.0, Small data: 0.0001\n","            'batch_size': 128, # Big data Lora: 32, Small data Lora: 16, Big data MLP: 512, Small data MLP: 128\n","            'epochs': 40, # Big data Lora: 8, Small data Lora: 25, Big data MLP: 20, Small data MLP: 30\n","            'margin': 0.05, # Options: 0.05\n","            'patience': 5, # Big data: 3, Small data: 5\n","            'min_delta': 0.0, # Options: 0.0\n","\n","            'lora_r': 16, # Big data: 16, Small data: 8\n","            'lora_alpha': 32, # Big data: 32, Small data: 8\n","            'lora_dropout': 0.2 # Big data: 0.02, Small data: 0.01\n","        },\n","\n","        'cnn': {\n","            'log_dir': '/vision_models/cnn_training',\n","            'load_dir': '/vision_models/cnn_backbone_models',\n","            'vision_model_training_name': 'Resnet50_Vanilla_First_Model', # Naming style: Clip50_Vanilla_First_Model\n","            'wandb_notes': 'Training run for the Vanilla ResNet50 model on no data.', # Naming style: Training run for the Vanilla ResNet50 model on no data. or Training run for the ResNet50 model on NIGHTS data.\n","\n","            'mlp': True,\n","            'normalize_embeds': True,\n","            'load_size': 224,\n","\n","            'dataset_root': None, # Options: /content/datasets/nights/, /content/datasets/fashion_triplets/\n","            'second_dataset_root': None, # Options: /content/datasets/fashion_triplets/\n","\n","            'lr': 0.0003, # Big data: 0.0003, Small data: 0.0001\n","            'weight_decay': 0.0001, # Big data: 0.0001, Small data: 0.0001\n","            'batch_size': 64, # Big data: 64, Small data: 32\n","            'epochs': 20, # Big data: 20, Small data: 40\n","            'margin': 0.05, # Options 0.05\n","            'patience': 3, # # Big data: 3, Small data: 5\n","            'min_delta': 0.0 # Options: 0\n","        }\n","    }\n","}\n","\n","config_dir = '/content/drive/MyDrive/perceptual-vits-fashion-forecasting/configs'\n","os.makedirs(config_dir, exist_ok=True)\n","config_path = os.path.join(config_dir, f\"{config['global']['experiment_name']}.yaml\")\n","\n","with open(config_path, 'w') as f:\n","    yaml.dump(config, f, default_flow_style=False)\n","\n","logging.info(f\"Config saved at: {config_path}\")"]}]}